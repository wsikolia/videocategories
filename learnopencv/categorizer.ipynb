{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a1b16c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import pafy\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from moviepy.editor import *\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c3468a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_constant = 23\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a87e144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 2160x2160 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a Matplotlib figure\n",
    "plt.figure(figsize = (30, 30))\n",
    "\n",
    "# Get Names of all classes in UCF50\n",
    "all_classes_names = os.listdir('UCF50')\n",
    "\n",
    "# Generate a random sample of images each time the cell runs\n",
    "random_range = random.sample(range(len(all_classes_names)), 20)\n",
    "\n",
    "# Iterating through all the random samples\n",
    "for counter, random_index in enumerate(random_range, 1):\n",
    "    # print(random_index)\n",
    "    # print(\"The counter is: \", counter)\n",
    "    # Getting Class Name using Random Index\n",
    "    selected_class_Name = all_classes_names[random_index]\n",
    "    \n",
    "    # Getting a list of all the video files present in a Class Directory\n",
    "    video_files_names_list = os.listdir(f'UCF50/{selected_class_Name}')\n",
    "\n",
    "    # Randomly selecting a video file\n",
    "    selected_video_file_name = random.choice(video_files_names_list)\n",
    "\n",
    "    # Reading the Video File Using the Video Capture\n",
    "    video_reader = cv2.VideoCapture(f'UCF50/{selected_class_Name}/{selected_video_file_name}')\n",
    "    \n",
    "    # Reading The First Frame of the Video File\n",
    "    _, bgr_frame = video_reader.read()\n",
    "\n",
    "    # Closing the VideoCapture object and releasing all resources. \n",
    "    video_reader.release()\n",
    "\n",
    "    # Converting the BGR Frame to RGB Frame \n",
    "    rgb_frame = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Adding The Class Name Text on top of the Video Frame.\n",
    "    cv2.putText(rgb_frame, #numpy array on which text is written\n",
    "                selected_class_Name, #text\n",
    "                (10, 30), #position at which writing has to start\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, #font family\n",
    "                1, #font size\n",
    "                (255, 0, 0), #font color\n",
    "                2) #font stroke\n",
    "    \n",
    "    # Assigning the Frame to a specific position of a subplot\n",
    "    plt.subplot(5, 4, counter)\n",
    "    plt.imshow(rgb_frame)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa6c1b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_height, image_width = 64, 64\n",
    "max_images_per_class = 8000\n",
    "dataset_directory = \"UCF50\"\n",
    "classes_list = [\"WalkingWithDog\", \"TaiChi\", \"Swing\", \"HorseRace\"]\n",
    "model_output_size = len(classes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34959586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frames_extraction(video_path):\n",
    "    # Empty List declared to store video frames\n",
    "    frames_list = []\n",
    "    \n",
    "    # Reading the Video File Using the VideoCapture\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Iterating through Video Frames\n",
    "    while True:\n",
    "\n",
    "        # Reading a frame from the video file \n",
    "        success, frame = video_reader.read() \n",
    "\n",
    "        # If Video frame was not successfully read then break the loop\n",
    "        # This means the end of the video files has been reached\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        # Resize the Frame to fixed Dimensions\n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "        \n",
    "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
    "        normalized_frame = resized_frame / 255\n",
    "        \n",
    "        # Appending the normalized frame into the frames list\n",
    "        frames_list.append(normalized_frame)\n",
    "    \n",
    "    # Closing the VideoCapture object and releasing all resources. \n",
    "    video_reader.release()\n",
    "\n",
    "    # returning the frames list \n",
    "    return frames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60eec0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "    # Declaring Empty Lists to store the features and labels values.\n",
    "    temp_features = [] \n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    # Iterating through all the classes mentioned in the classes list\n",
    "    for class_index, class_name in enumerate(classes_list):\n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "        \n",
    "        # Getting the list of video files present in the specific class name directory\n",
    "        # In this case our dataset_directory is the \"UCF50\" drectory\n",
    "        files_list = os.listdir(os.path.join(dataset_directory, class_name))\n",
    "\n",
    "        # Iterating through all the files present in the files list\n",
    "        for file_name in files_list:\n",
    "\n",
    "            # Construct the complete video path\n",
    "            video_file_path = os.path.join(dataset_directory, class_name, file_name)\n",
    "\n",
    "            # Calling the frame_extraction method for every video file path\n",
    "            frames = frames_extraction(video_file_path)\n",
    "\n",
    "            # Appending the frames to a temporary list.\n",
    "            temp_features.extend(frames)\n",
    "        \n",
    "        # Adding randomly selected frames to the features list\n",
    "        features.extend(random.sample(temp_features, max_images_per_class))\n",
    "\n",
    "        # Adding Fixed number of labels to the labels list\n",
    "        labels.extend([class_index] * max_images_per_class)\n",
    "        \n",
    "        # Emptying the temp_features list so it can be reused to store all frames of the next class.\n",
    "        temp_features.clear()\n",
    "\n",
    "    # Converting the features and labels lists to numpy arrays\n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)  \n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4152f4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data of Class: WalkingWithDog\n",
      "Extracting Data of Class: TaiChi\n",
      "Extracting Data of Class: Swing\n",
      "Extracting Data of Class: HorseRace\n"
     ]
    }
   ],
   "source": [
    "features, labels = create_dataset()\n",
    "# Using Keras's to_categorical method to convert labels into one-hot-encoded vectors\n",
    "one_hot_encoded_labels = to_categorical(labels)\n",
    "# split the data set into train and test sets.\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels,\n",
    "                                                                            test_size = 0.2, shuffle = True,\n",
    "                                                                            random_state = seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d4ccf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 60, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 60, 60, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 57,668\n",
      "Trainable params: 57,028\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "Model Created Successfully!\n"
     ]
    }
   ],
   "source": [
    "# Let's create a function that will construct our model\n",
    "def create_model():\n",
    "\n",
    "    # We will use a Sequential model for model construction\n",
    "    model = Sequential()\n",
    "\n",
    "    # Defining The Model Architecture\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu',\n",
    "                     input_shape = (image_height, image_width, 3)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(model_output_size, activation = 'softmax'))\n",
    "\n",
    "    # Printing the models summary\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Calling the create_model method\n",
    "model = create_model()\n",
    "\n",
    "print(\"Model Created Successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6d835a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "plot_model(model, to_file = 'model_structure_plot.png', show_shapes = True, show_layer_names = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7959d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the Early Stopping Callback to the model which will continuously monitor the validation loss metric for every epoch.\n",
    "# If the models validation loss does not decrease after 15 consecutive epochs, the training will be stopped and the weight which reported the lowest validation loss will be retored in the model.\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 15, mode = 'min', restore_best_weights = True)\n",
    "\n",
    "# Adding loss, optimizer and metrics values to the model.\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "# Start Training\n",
    "model_training_history = model.fit(x = features_train, y = labels_train, epochs = 5,\n",
    "                                   batch_size = 4 , shuffle = True, validation_split = 0.2,\n",
    "                                   callbacks = [early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dcba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a useful name for our model, incase you're saving multiple models (OPTIONAL)\n",
    "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
    "current_date_time_dt = dt.datetime.now()\n",
    "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
    "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
    "model_name = f'Model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
    "\n",
    "# Saving your Model\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a50c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(metric_name_1, metric_name_2, plot_name):\n",
    "  # Get Metric values using metric names as identifiers\n",
    "  metric_value_1 = model_training_history.history[metric_name_1]\n",
    "  metric_value_2 = model_training_history.history[metric_name_2]\n",
    "\n",
    "  # Constructing a range object which will be used as time \n",
    "  epochs = range(len(metric_value_1))\n",
    "  \n",
    "  # Plotting the Graph\n",
    "  plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
    "  plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
    "  \n",
    "  # Adding title to the plot\n",
    "  plt.title(str(plot_name))\n",
    "\n",
    "  # Adding legend to the plot\n",
    "  plt.legend()\n",
    "plot_metric('loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c361433",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_youtube_videos(youtube_video_url, output_directory):\n",
    "    # Creating a Video object which includes useful information regarding the youtube video.\n",
    "    video = pafy.new(youtube_video_url)\n",
    "\n",
    "    # Getting the best available quality object for the youtube video.\n",
    "    video_best = video.getbest()\n",
    "\n",
    "    # Constructing the Output File Path\n",
    "    output_file_path = f'{output_directory}/{video.title}.mp4'\n",
    "\n",
    "    # Downloading the youtube video at the best available quality.\n",
    "    video_best.download(filepath = output_file_path, quiet = True)\n",
    "\n",
    "    # Returning Video Title\n",
    "    return video.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8927528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_live_video(video_file_path, output_file_path, window_size):\n",
    "\n",
    "    # Initialize a Deque Object with a fixed size which will be used to implement moving/rolling average functionality.\n",
    "    predicted_labels_probabilities_deque = deque(maxlen = window_size)\n",
    "\n",
    "    # Reading the Video File using the VideoCapture Object\n",
    "    video_reader = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "    # Getting the width and height of the video \n",
    "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Writing the Overlayed Video Files Using the VideoWriter Object\n",
    "    video_writer = cv2.VideoWriter(output_file_path, cv2.VideoWriter_fourcc('M', 'P', '4', 'V'), 24, (original_video_width, original_video_height))\n",
    "\n",
    "    while True: \n",
    "\n",
    "        # Reading The Frame\n",
    "        status, frame = video_reader.read() \n",
    "\n",
    "        if not status:\n",
    "            break\n",
    "\n",
    "        # Resize the Frame to fixed Dimensions\n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "        \n",
    "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
    "        normalized_frame = resized_frame / 255\n",
    "\n",
    "        # Passing the Image Normalized Frame to the model and receiving Predicted Probabilities.\n",
    "        predicted_labels_probabilities = model.predict(np.expand_dims(normalized_frame, axis = 0))[0]\n",
    "\n",
    "        # Appending predicted label probabilities to the deque object\n",
    "        predicted_labels_probabilities_deque.append(predicted_labels_probabilities)\n",
    "\n",
    "        # Assuring that the Deque is completely filled before starting the averaging process\n",
    "        if len(predicted_labels_probabilities_deque) == window_size:\n",
    "\n",
    "            # Converting Predicted Labels Probabilities Deque into Numpy array\n",
    "            predicted_labels_probabilities_np = np.array(predicted_labels_probabilities_deque)\n",
    "\n",
    "            # Calculating Average of Predicted Labels Probabilities Column Wise \n",
    "            predicted_labels_probabilities_averaged = predicted_labels_probabilities_np.mean(axis = 0)\n",
    "\n",
    "            # Converting the predicted probabilities into labels by returning the index of the maximum value.\n",
    "            predicted_label = np.argmax(predicted_labels_probabilities_averaged)\n",
    "\n",
    "            # Accessing The Class Name using predicted label.\n",
    "            predicted_class_name = classes_list[predicted_label]\n",
    "          \n",
    "            # Overlaying Class Name Text Ontop of the Frame\n",
    "            cv2.putText(frame, predicted_class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # Writing The Frame\n",
    "        video_writer.write(frame)\n",
    "\n",
    "\n",
    "        # cv2.imshow('Predicted Frames', frame)\n",
    "\n",
    "        # key_pressed = cv2.waitKey(10)\n",
    "\n",
    "        # if key_pressed == ord('q'):\n",
    "        #     break\n",
    "\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "    # Closing the VideoCapture and VideoWriter objects and releasing all resources held by them. \n",
    "    video_reader.release()\n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad2829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating The Output directories if it does not exist\n",
    "output_directory = 'Youtube_Videos'\n",
    "os.makedirs(output_directory, exist_ok = True)\n",
    "\n",
    "# Downloading a YouTube Video\n",
    "video_title = download_youtube_videos('https://www.youtube.com/watch?v=8u0qjmHIOcE', output_directory)\n",
    "\n",
    "# Getting the YouTube Video's path you just downloaded\n",
    "input_video_file_path = f'{output_directory}/{video_title}.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b073ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting sthe Widow Size which will be used by the Rolling Averge Process\n",
    "window_size = 1\n",
    "\n",
    "# Construting The Output YouTube Video Path\n",
    "output_video_file_path = f'{output_directory}/{video_title} -Output-WSize {window_size}.mp4'\n",
    "\n",
    "# Calling the predict_on_live_video method to start the Prediction.\n",
    "predict_on_live_video(input_video_file_path, output_video_file_path, window_size)\n",
    "\n",
    "# Play Video File in the Notebook\n",
    "VideoFileClip(output_video_file_path).ipython_display(width = 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b291f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the Widow Size which will be used by the Rolling Averge Process\n",
    "window_size = 25\n",
    "\n",
    "# Construting The Output YouTube Video Path\n",
    "output_video_file_path = f'{output_directory}/{video_title} -Output-WSize {window_size}.mp4'\n",
    "\n",
    "# Calling the predict_on_live_video method to start the Prediction and Rolling Averge Process\n",
    "predict_on_live_video(input_video_file_path, output_video_file_path, window_size)\n",
    "\n",
    "# Play Video File in the Notebook\n",
    "VideoFileClip(output_video_file_path).ipython_display(width = 700)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
